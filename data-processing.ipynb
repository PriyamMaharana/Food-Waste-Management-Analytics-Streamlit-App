{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = \"dataset/providers_data.csv\"\n",
    "filepath2 = \"dataset/receivers_data.csv\"\n",
    "filepath3 = \"dataset/claims_data.csv\"\n",
    "filepath4 = \"dataset/food_listings_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Provider Null: Provider_ID    0\n",
      "Name           0\n",
      "Type           0\n",
      "Address        0\n",
      "City           0\n",
      "Contact        0\n",
      "dtype: int64\n",
      "\n",
      "Provider Duplicate: 0\n"
     ]
    }
   ],
   "source": [
    "provider_df = pd.read_csv(filepath1)\n",
    "\n",
    "provider_null = provider_df.isnull().sum()\n",
    "provider_dupli = provider_df.duplicated().sum()\n",
    "\n",
    "print(f'\\nProvider Null: {provider_null}')\n",
    "print(f'\\nProvider Duplicate: {provider_dupli}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gonzales-Cochran</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>74347 Christopher Extensions\\nAndreamouth, OK ...</td>\n",
       "      <td>New Jessica</td>\n",
       "      <td>+1-600-220-0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nielsen, Johnson and Fuller</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>91228 Hanson Stream\\nWelchtown, OR 27136</td>\n",
       "      <td>East Sheena</td>\n",
       "      <td>+1-925-283-8901x6297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Miller-Black</td>\n",
       "      <td>Supermarket</td>\n",
       "      <td>561 Martinez Point Suite 507\\nGuzmanchester, W...</td>\n",
       "      <td>Lake Jesusview</td>\n",
       "      <td>001-517-295-2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Clark, Prince and Williams</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>467 Bell Trail Suite 409\\nPort Jesus, IA 61188</td>\n",
       "      <td>Mendezmouth</td>\n",
       "      <td>556.944.8935x401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Coleman-Farley</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>078 Matthew Creek Apt. 319\\nSaraborough, MA 53978</td>\n",
       "      <td>Valentineside</td>\n",
       "      <td>193.714.6577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Vasquez, Ruiz and Flowers</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>84308 Justin Stravenue\\nNew Amberside, NE 53447</td>\n",
       "      <td>Williamview</td>\n",
       "      <td>+1-319-378-7627x0682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Garza-Williams</td>\n",
       "      <td>Catering Service</td>\n",
       "      <td>08864 Figueroa Radial Suite 948\\nJennaberg, AZ...</td>\n",
       "      <td>East Rossside</td>\n",
       "      <td>001-924-441-3963x746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Novak Group</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>934 Zachary Run\\nMelissamouth, WY 02729</td>\n",
       "      <td>Joshuastad</td>\n",
       "      <td>(903)642-1969x3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Moody Ltd</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>17580 Ernest Hills\\nLake Michaelmouth, OR 56416</td>\n",
       "      <td>Stevenchester</td>\n",
       "      <td>637.300.3664x4880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>Jenkins-Brooks</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>53390 Evans Rapids Suite 982\\nLake Meghan, MO ...</td>\n",
       "      <td>Brendantown</td>\n",
       "      <td>266-324-3458x95775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Provider_ID                         Name              Type  \\\n",
       "0              1             Gonzales-Cochran       Supermarket   \n",
       "1              2  Nielsen, Johnson and Fuller     Grocery Store   \n",
       "2              3                 Miller-Black       Supermarket   \n",
       "3              4   Clark, Prince and Williams     Grocery Store   \n",
       "4              5               Coleman-Farley     Grocery Store   \n",
       "..           ...                          ...               ...   \n",
       "995          996    Vasquez, Ruiz and Flowers        Restaurant   \n",
       "996          997               Garza-Williams  Catering Service   \n",
       "997          998                  Novak Group     Grocery Store   \n",
       "998          999                    Moody Ltd     Grocery Store   \n",
       "999         1000               Jenkins-Brooks        Restaurant   \n",
       "\n",
       "                                               Address            City  \\\n",
       "0    74347 Christopher Extensions\\nAndreamouth, OK ...     New Jessica   \n",
       "1             91228 Hanson Stream\\nWelchtown, OR 27136     East Sheena   \n",
       "2    561 Martinez Point Suite 507\\nGuzmanchester, W...  Lake Jesusview   \n",
       "3       467 Bell Trail Suite 409\\nPort Jesus, IA 61188     Mendezmouth   \n",
       "4    078 Matthew Creek Apt. 319\\nSaraborough, MA 53978   Valentineside   \n",
       "..                                                 ...             ...   \n",
       "995    84308 Justin Stravenue\\nNew Amberside, NE 53447     Williamview   \n",
       "996  08864 Figueroa Radial Suite 948\\nJennaberg, AZ...   East Rossside   \n",
       "997            934 Zachary Run\\nMelissamouth, WY 02729      Joshuastad   \n",
       "998    17580 Ernest Hills\\nLake Michaelmouth, OR 56416   Stevenchester   \n",
       "999  53390 Evans Rapids Suite 982\\nLake Meghan, MO ...     Brendantown   \n",
       "\n",
       "                  Contact  \n",
       "0         +1-600-220-0480  \n",
       "1    +1-925-283-8901x6297  \n",
       "2        001-517-295-2206  \n",
       "3        556.944.8935x401  \n",
       "4            193.714.6577  \n",
       "..                    ...  \n",
       "995  +1-319-378-7627x0682  \n",
       "996  001-924-441-3963x746  \n",
       "997    (903)642-1969x3300  \n",
       "998     637.300.3664x4880  \n",
       "999    266-324-3458x95775  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Provider Duplicate: 1\n",
      "\n",
      "Provider Null:\n",
      "provider_id    0\n",
      "name           0\n",
      "type           0\n",
      "address        0\n",
      "city           0\n",
      "contact        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'Address' in provider_df.columns:\n",
    "    provider_df['Address'] = provider_df['Address'].astype(str).replace(r'[\\n,]', ' ', regex=True)\n",
    "\n",
    "# --- Contact normalization ---\n",
    "def normalize_contact(contact):\n",
    "    if pd.isna(contact):\n",
    "        return \"\"\n",
    "    contact = str(contact).strip()\n",
    "    contact = re.sub(r'(?i)[\\s\\-.,]*(ext|x)[\\s\\-.,]*\\d+', '', contact)\n",
    "    main = re.sub(r'[^\\d+]', '', contact)\n",
    "    if not main:\n",
    "        return \"\"\n",
    "    if main.startswith('00'):\n",
    "        main = '+' + main[2:]\n",
    "    if not main.startswith('+'):\n",
    "        if len(main) == 10:\n",
    "            main = '+1' + main\n",
    "        else:\n",
    "            main = '+' + main\n",
    "    return main\n",
    "\n",
    "if 'Contact' in provider_df.columns:\n",
    "    provider_df['Contact'] = provider_df['Contact'].apply(normalize_contact)\n",
    "\n",
    "# --- Name normalization ---\n",
    "def split_and_normalize_names(name):\n",
    "    if pd.isna(name):\n",
    "        return [\"\"]\n",
    "    name = str(name).replace('\"', '').replace(\"'\", '')\n",
    "    parts = re.split(r'(?i)(?:,|\\s+and\\s+|\\s+&\\s+)', name)\n",
    "    parts = [re.sub(r'[-,]', ' ', n).strip() for n in parts]\n",
    "    return [re.sub(r'\\s+', ' ', n).strip() for n in parts if n.strip()]\n",
    "\n",
    "if 'Name' in provider_df.columns:\n",
    "    provider_df['Name_Split'] = provider_df['Name'].apply(split_and_normalize_names)\n",
    "    provider_df = provider_df.explode('Name_Split').copy()\n",
    "    provider_df['Name'] = provider_df['Name_Split']\n",
    "    provider_df.drop(columns=['Name_Split'], inplace=True)\n",
    "\n",
    "# --- Lowercase columns ---\n",
    "provider_df.columns = provider_df.columns.str.lower()\n",
    "\n",
    "# --- Save CSV ---\n",
    "provider_df.to_csv('provider_data_cleaned.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# --- Validation ---\n",
    "prov_dup = pd.read_csv('provider_data_cleaned.csv', encoding='utf-8')\n",
    "print(f'\\nProvider Duplicate: {prov_dup.duplicated().sum()}')\n",
    "print(f'\\nProvider Null:\\n{prov_dup.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Provider Null: Receiver_ID    0\n",
      "Name           0\n",
      "Type           0\n",
      "City           0\n",
      "Contact        0\n",
      "dtype: int64\n",
      "\n",
      "Provider Duplicate: 0\n"
     ]
    }
   ],
   "source": [
    "receiver_df = pd.read_csv(filepath2)\n",
    "\n",
    "receiver_null = receiver_df.isnull().sum()\n",
    "receiver_dupli = receiver_df.duplicated().sum()\n",
    "\n",
    "print(f'\\nProvider Null: {receiver_null}')\n",
    "print(f'\\nProvider Duplicate: {receiver_dupli}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Receiver Duplicate: 0\n",
      "\n",
      "Receiver Null:\n",
      "receiver_id    0\n",
      "name           0\n",
      "type           0\n",
      "city           0\n",
      "contact        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'City' in receiver_df.columns:\n",
    "    receiver_df['City'] = receiver_df['City'].astype(str).replace(r'[\\n,]', ' ', regex=True)\n",
    "\n",
    "# 2. Normalize Contact\n",
    "def normalize_contact(contact):\n",
    "    if pd.isna(contact):\n",
    "        return \"\"\n",
    "    contact = str(contact).strip()\n",
    "    contact = re.sub(r'(?i)[\\s\\-.,]*(ext|x)[\\s\\-.,]*\\d+', '', contact)\n",
    "    main = re.sub(r'[^\\d+]', '', contact)\n",
    "    if not main:\n",
    "        return \"\"\n",
    "    if main.startswith('00'):\n",
    "        main = '+' + main[2:]\n",
    "    if not main.startswith('+'):\n",
    "        if len(main) == 10:\n",
    "            main = '+1' + main\n",
    "        else:\n",
    "            main = '+' + main\n",
    "    return main\n",
    "\n",
    "if 'Contact' in receiver_df.columns:\n",
    "    receiver_df['Contact'] = receiver_df['Contact'].apply(normalize_contact)\n",
    "\n",
    "# 3. Normalize Name and split\n",
    "def split_and_normalize_names(name):\n",
    "    if pd.isna(name):\n",
    "        return [\"\"]\n",
    "    name = str(name).replace('\"', '').replace(\"'\", '')\n",
    "    parts = re.split(r'(?i)(?:,|\\s+and\\s+|\\s+&\\s+)', name)\n",
    "    parts = [re.sub(r'[-,]', ' ', p).strip() for p in parts]\n",
    "    return [re.sub(r'\\s+', ' ', p).strip() for p in parts if p.strip()]\n",
    "\n",
    "if 'Name' in receiver_df.columns:\n",
    "    receiver_df['Name_Split'] = receiver_df['Name'].apply(split_and_normalize_names)\n",
    "    receiver_df = receiver_df.explode('Name_Split').copy()\n",
    "    receiver_df['Name'] = receiver_df['Name_Split']\n",
    "    receiver_df.drop(columns=['Name_Split'], inplace=True)\n",
    "\n",
    "# 4. Lowercase column names\n",
    "receiver_df.columns = receiver_df.columns.str.lower()\n",
    "\n",
    "# 5. Save cleaned data\n",
    "receiver_df.to_csv('receiver_data_cleaned.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# 6. Validation\n",
    "recev_dup = pd.read_csv('receiver_data_cleaned.csv', encoding='utf-8')\n",
    "print(f'\\nReceiver Duplicate: {recev_dup.duplicated().sum()}')\n",
    "print(f'\\nReceiver Null:\\n{recev_dup.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food Null: Food_ID          0\n",
      "Food_Name        0\n",
      "Quantity         0\n",
      "Expiry_Date      0\n",
      "Provider_ID      0\n",
      "Provider_Type    0\n",
      "Location         0\n",
      "Food_Type        0\n",
      "Meal_Type        0\n",
      "dtype: int64\n",
      "\n",
      "Food Duplicate: 0\n"
     ]
    }
   ],
   "source": [
    "food_df = pd.read_csv(filepath4)\n",
    "\n",
    "food_null = food_df.isnull().sum()\n",
    "food_dupli = food_df.duplicated().sum()\n",
    "\n",
    "print(f'\\nFood Null: {food_null}')\n",
    "print(f'\\nFood Duplicate: {food_dupli}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food Duplicate rows: 0\n",
      "\n",
      "Food Null counts:\n",
      "food_id          0\n",
      "food_name        0\n",
      "quantity         0\n",
      "expiry_date      0\n",
      "provider_id      0\n",
      "provider_type    0\n",
      "location         0\n",
      "food_type        0\n",
      "meal_type        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyam Maharana\\AppData\\Local\\Temp\\ipykernel_12052\\3303304315.py:30: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  food_df['Expiry_Date'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Make mapping keys lowercase for consistency\n",
    "food_category_mapping = {\n",
    "    'bread': 'Vegetarian',       # if dairy-free, else Vegetarian\n",
    "    'vegetables': 'Vegan',\n",
    "    'pasta': 'Vegetarian',       # if egg-free, else Vegetarian\n",
    "    'soup': 'Vegetarian',        # if no dairy/broth, else Vegetarian\n",
    "    'salad': 'Vegan',\n",
    "    'rice': 'Vegan',\n",
    "    'fruits': 'Vegan',\n",
    "    'dairy': 'Vegetarian',\n",
    "    'fish': 'Non Vegetarian',\n",
    "    'chicken': 'Non Vegetarian'\n",
    "}\n",
    "\n",
    "\n",
    "# Clean 'Food_Type' â€“ replace hyphens with spaces\n",
    "if 'Food_Type' in food_df.columns:\n",
    "    food_df['Food_Type'] = food_df['Food_Type'].astype(str).replace(r'[-]', ' ', regex=True)\n",
    "    \n",
    "# Clean 'Location' â€“ remove newlines and commas\n",
    "if 'Location' in food_df.columns:\n",
    "    food_df['Location'] = food_df['Location'].astype(str).replace(r'[\\n,]', ' ', regex=True)\n",
    "\n",
    "# Clean 'Food_Name' â€“ remove newlines and commas\n",
    "if 'Food_Name' in food_df.columns:\n",
    "    food_df['Food_Name'] = food_df['Food_Name'].astype(str).replace(r'[\\n,]', ' ', regex=True)\n",
    "\n",
    "# Clean and format 'Expiry_Date'\n",
    "if 'Expiry_Date' in food_df.columns:\n",
    "    food_df['Expiry_Date'] = pd.to_datetime(\n",
    "        food_df['Expiry_Date'],\n",
    "        dayfirst=True,\n",
    "        errors='coerce'  # invalid dates become NaT\n",
    "    ).dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# --- Auto-fill Food_Type using partial match from Food_Name ---\n",
    "def map_food_type(name):\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    name = str(name).lower()\n",
    "    for key, value in food_category_mapping.items():\n",
    "        if key in name:  # partial match\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "if 'Food_Type' in food_df.columns and 'Food_Name' in food_df.columns:\n",
    "    food_df['Food_Type'] = food_df['Food_Name'].apply(map_food_type)\n",
    "\n",
    "# Lowercase all column names for DB compatibility\n",
    "food_df.columns = food_df.columns.str.lower()\n",
    "\n",
    "# Save cleaned data with UTF-8 encoding\n",
    "food_df.to_csv('food_data_cleaned.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Reload for validation\n",
    "food_dup = pd.read_csv('food_data_cleaned.csv', encoding='utf-8')\n",
    "print(f'\\nFood Duplicate rows: {food_dup.duplicated().sum()}')\n",
    "print(f'\\nFood Null counts:\\n{food_dup.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim Null: Claim_ID       0\n",
      "Food_ID        0\n",
      "Receiver_ID    0\n",
      "Status         0\n",
      "Timestamp      0\n",
      "dtype: int64\n",
      "\n",
      "Claim Duplicate: 0\n"
     ]
    }
   ],
   "source": [
    "claim_df = pd.read_csv(filepath3)\n",
    "\n",
    "claim_null = claim_df.isnull().sum()\n",
    "claim_dupli = claim_df.duplicated().sum()\n",
    "\n",
    "print(f'\\nClaim Null: {claim_null}')\n",
    "print(f'\\nClaim Duplicate: {claim_dupli}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim Duplicate: 0\n",
      "\n",
      "Claim Null: claim_id       0\n",
      "food_id        0\n",
      "receiver_id    0\n",
      "status         0\n",
      "timestamp      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean and format 'Timestamp'\n",
    "if 'Timestamp' in claim_df.columns:\n",
    "    claim_df['Timestamp'] = pd.to_datetime(\n",
    "        claim_df['Timestamp'],\n",
    "        dayfirst=True,\n",
    "        errors='coerce'  # invalid dates become NaT\n",
    "    ).dt.strftime('%d-%m-%Y %H:%M')\n",
    "\n",
    "\n",
    "claim_df.columns = claim_df.columns.str.lower()\n",
    "claim_df.to_csv('claim_data_cleaned.csv', index=False)\n",
    "\n",
    "\n",
    "claim_dup = pd.read_csv('claim_data_cleaned.csv')\n",
    "print(f'\\nClaim Duplicate: {claim_dup.duplicated().sum()}')\n",
    "print(f'\\nClaim Null: {claim_dup.isnull().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
